{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Heart Failure AutoML pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"\n",
    "PROJECT = !(gcloud config get-value project)\n",
    "PROJECT = PROJECT[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/home/jupyter/.local/bin:/usr/local/cuda/bin:/opt/conda/bin:/opt/conda/condabin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n"
     ]
    }
   ],
   "source": [
    "# Set `PATH` to include the directory containing KFP CLI\n",
    "PATH = %env PATH\n",
    "%env PATH=/home/jupyter/.local/bin:{PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Build the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the pipeline to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./pipelines/kfp_heart_failure_automl_pipeline.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./pipelines/kfp_heart_failure_automl_pipeline.py\n",
    "# Copyright 2021 Google LLC\n",
    "\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n",
    "# use this file except in compliance with the License. You may obtain a copy of\n",
    "# the License at\n",
    "\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\"\n",
    "# BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n",
    "# express or implied. See the License for the specific language governing\n",
    "# permissions and limitations under the License.\n",
    "\n",
    "\"\"\"Kubeflow Heart Failure Pipeline.\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "from google_cloud_pipeline_components.aiplatform import (\n",
    "    AutoMLTabularTrainingJobRunOp,\n",
    "    EndpointCreateOp,\n",
    "    ModelDeployOp,\n",
    "    TabularDatasetCreateOp,\n",
    ")\n",
    "from kfp.v2 import dsl\n",
    "\n",
    "PIPELINE_ROOT = os.getenv(\"PIPELINE_ROOT\")\n",
    "PROJECT = os.getenv(\"PROJECT\")\n",
    "DATASET_SOURCE = os.getenv(\"DATASET_SOURCE\")\n",
    "PIPELINE_NAME = os.getenv(\"PIPELINE_NAME\", \"kfp-heartfailure\")\n",
    "DISPLAY_NAME = os.getenv(\"MODEL_DISPLAY_NAME\", PIPELINE_NAME)\n",
    "TARGET_COLUMN = os.getenv(\"TARGET_COLUMN\", \"HeartDisease\")\n",
    "SERVING_MACHINE_TYPE = os.getenv(\"SERVING_MACHINE_TYPE\", \"n1-standard-4\")\n",
    "SPLIT_COLUMN = os.getenv(\"SPLIT_COLUMN\", \"split\")\n",
    "OPTIMIZATION_OBJECTIVE = os.getenv(\"OPTIMIZATION_OBJECTIVE\", \"maximize-au-roc\")\n",
    "BUDGET_MILLI_NODE_HOURS = os.getenv(\"BUDGET_MILLI_NODE_HOURS\", \"2000\")\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name=f\"{PIPELINE_NAME}-vertex-automl-pipeline\",\n",
    "    description=f\"AutoML Vertex Pipeline for {PIPELINE_NAME}\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    ")\n",
    "def create_pipeline():\n",
    "\n",
    "    dataset_create_task = TabularDatasetCreateOp(\n",
    "        display_name=DISPLAY_NAME,\n",
    "        gcs_source=DATASET_SOURCE,\n",
    "        project=PROJECT,\n",
    "    )\n",
    "\n",
    "    automl_training_task = AutoMLTabularTrainingJobRunOp(\n",
    "        project=PROJECT,\n",
    "        display_name=DISPLAY_NAME,\n",
    "        optimization_prediction_type=\"classification\",\n",
    "        dataset=dataset_create_task.outputs[\"dataset\"],\n",
    "        target_column=TARGET_COLUMN,\n",
    "        predefined_split_column_name=SPLIT_COLUMN,\n",
    "        optimization_objective=OPTIMIZATION_OBJECTIVE,\n",
    "        budget_milli_node_hours=BUDGET_MILLI_NODE_HOURS,\n",
    "    )\n",
    "\n",
    "    endpoint_create_task = EndpointCreateOp(\n",
    "        project=PROJECT,\n",
    "        display_name=DISPLAY_NAME,\n",
    "        description=\"Heart Failure AutoML model\",\n",
    "    )\n",
    "\n",
    "    model_deploy_task = ModelDeployOp(  # pylint: disable=unused-variable\n",
    "        model=automl_training_task.outputs[\"model\"],\n",
    "        endpoint=endpoint_create_task.outputs[\"endpoint\"],\n",
    "        deployed_model_display_name=DISPLAY_NAME,\n",
    "        dedicated_resources_machine_type=SERVING_MACHINE_TYPE,\n",
    "        dedicated_resources_min_replica_count=1,\n",
    "        dedicated_resources_max_replica_count=1,\n",
    "        #enable_access_logging=True, #comment out because of failure\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the environment variables that will be passed to the pipeline compiler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PIPELINE_ROOT=gs://qwiklabs-asl-02-99f66d8df225-kfp-artifact-store/pipeline\n",
      "env: PROJECT=qwiklabs-asl-02-99f66d8df225\n",
      "env: REGION=us-central1\n",
      "env: DATASET_SOURCE=gs://qwiklabs-asl-02-99f66d8df225/heart_failure/scaled-engineered-heart.csv\n"
     ]
    }
   ],
   "source": [
    "ARTIFACT_STORE = f\"gs://{PROJECT}-kfp-artifact-store\"\n",
    "PIPELINE_ROOT = f\"{ARTIFACT_STORE}/pipeline\"\n",
    "#DATASET_SOURCE = f\"bq://{PROJECT}.covertype_dataset.covertype\"\n",
    "DATASET_SOURCE = f\"gs://{PROJECT}/heart_failure/scaled-engineered-heart.csv\"\n",
    "\n",
    "%env PIPELINE_ROOT={PIPELINE_ROOT}\n",
    "%env PROJECT={PROJECT}\n",
    "%env REGION={REGION}\n",
    "%env DATASET_SOURCE={DATASET_SOURCE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the `ARTIFACT_STORE` has been created, and let us create it if not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://qwiklabs-asl-02-99f66d8df225-kfp-artifact-store/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls | grep ^{ARTIFACT_STORE}/$ || gsutil mb -l {REGION} {ARTIFACT_STORE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the CLI compiler to compile the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the pipeline from the Python file we generated into a JSON description using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_JSON = \"pipelines/kfp_heart_failure_automl_pipeline.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/kfp/v2/compiler/compiler.py:1293: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
      "  category=FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "!dsl-compile-v2 --py pipelines/kfp_heart_failure_automl_pipeline.py --output $PIPELINE_JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** You can also use the Python SDK to compile the pipeline:\n",
    "\n",
    "```python\n",
    "from kfp.v2 import compiler\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=create_pipeline, \n",
    "    package_path=PIPELINE_JSON,\n",
    ")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is the pipeline file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"pipelineSpec\": {\n",
      "    \"components\": {\n",
      "      \"comp-automl-tabular-training-job\": {\n",
      "        \"executorLabel\": \"exec-automl-tabular-training-job\",\n",
      "        \"inputDefinitions\": {\n",
      "          \"artifacts\": {\n",
      "            \"dataset\": {\n",
      "              \"artifactType\": {\n",
      "                \"schemaTitle\": \"google.VertexDataset\",\n"
     ]
    }
   ],
   "source": [
    "!head {PIPELINE_JSON}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the pipeline package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions for class:\n",
    "\n",
    "I hit this error - The replica workerpool0-0 exited with a non-zero status of 13. To find out more about why your job exited please check the logs: https://console.cloud.google.com/logs/viewer?project=9475810701&resource=ml_job%2Fjob_id%2F3079020273060544512&advancedFilter=resource.type%3D%22ml_job%22%0Aresource.labels.job_id%3D%223079020273060544512%22\n",
    "\n",
    "- how do I restart a pipeline at a failed step?\n",
    "- How do I get permissions to view this log - https://console.cloud.google.com/logs/viewer?project=9475810701&resource=ml_job%2Fjob_id%2F3079020273060544512&advancedFilter=resource.type%3D%22ml_job%22%0Aresource.labels.job_id%3D%223079020273060544512%22\n",
    "- How do I debug this error: The replica workerpool0-0 exited with a non-zero status of 13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/kfp-heartfailure-vertex-automl-pipeline-20230205204728?project=9475810701\n",
      "PipelineJob projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/9475810701/locations/us-central1/pipelineJobs/kfp-heartfailure-vertex-automl-pipeline-20230205204728\n"
     ]
    }
   ],
   "source": [
    "aiplatform.init(project=PROJECT, location=REGION)\n",
    "\n",
    "pipeline = aiplatform.PipelineJob(\n",
    "    display_name=\"kfp_heart_failure_automl_pipeline\",\n",
    "    template_path=PIPELINE_JSON,\n",
    "    enable_caching=True,\n",
    ")\n",
    "\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2021 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m103"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
